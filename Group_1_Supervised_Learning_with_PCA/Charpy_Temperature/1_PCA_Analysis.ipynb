{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badb884a",
   "metadata": {},
   "source": [
    "# PCA Analysis for Charpy Temperature Prediction\n",
    "\n",
    "## Why PCA for Charpy Temperature?\n",
    "\n",
    "**Problem**: The dataset contains 50+ features including chemical composition, welding parameters, and process conditions. Many of these features are highly correlated.\n",
    "\n",
    "**Why PCA is necessary**:\n",
    "\n",
    "1. **Multicollinearity**: Chemical elements like C, Mn, Si are often correlated due to steel composition requirements. This creates redundant information and unstable model coefficients.\n",
    "\n",
    "2. **Dimensionality Curse**: With sufficient samples and 50+ features, PCA reduces features while retaining 90-95% of variance, improving model generalization.\n",
    "\n",
    "3. **Noise Reduction**: Minor variations in measurements contribute little to prediction but add noise. PCA captures systematic variation while filtering noise.\n",
    "\n",
    "4. **Computational Efficiency**: Training models on 15-20 principal components is faster than 50+ original features, especially for GridSearchCV with cross-validation.\n",
    "\n",
    "**About Charpy Temperature**: Charpy Temperature (°C) is the testing temperature at which the Charpy impact test is performed. It's a critical parameter for assessing material toughness at different temperatures, especially important for applications in cold environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ddb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import KNNImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31312ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('pca_model', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../welddatabase/welddb_pca.csv')\n",
    "print(f\"Prepared dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Charpy Temperature data availability\n",
    "charpy_temp_available = df['Charpy_Temp_C'].notna().sum()\n",
    "print(f\"Charpy Temperature data available: {charpy_temp_available} samples ({charpy_temp_available/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f261e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = ['Yield_Strength_MPa', 'UTS_MPa', 'Elongation_%', \n",
    "                  'Reduction_Area_%', 'Charpy_Temp_C', 'Charpy_Energy_J',\n",
    "                  'Hardness_kg_mm2', 'FATT_50%', 'Primary_Ferrite_%',\n",
    "                  'Ferrite_2nd_Phase_%', 'Acicular_Ferrite_%', 'Martensite_%',\n",
    "                  'Ferrite_Carbide_%']\n",
    "\n",
    "df_charpy_temp = df[df['Charpy_Temp_C'].notna()].copy()\n",
    "y = df_charpy_temp['Charpy_Temp_C'].copy()\n",
    "X = df_charpy_temp.drop(columns=target_columns)\n",
    "\n",
    "print(f\"Samples with Charpy Temperature: {len(df_charpy_temp)}\")\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nCharpy Temperature statistics:\")\n",
    "print(f\"  Mean: {y.mean():.2f}°C\")\n",
    "print(f\"  Std: {y.std():.2f}°C\")\n",
    "print(f\"  Range: [{y.min():.2f}°C, {y.max():.2f}°C]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8849fc85",
   "metadata": {},
   "source": [
    "## Feature Imputation\n",
    "\n",
    "**Why KNN Imputer?**\n",
    "\n",
    "KNN Imputer is robust to different missing data mechanisms (MCAR, MAR, MNAR) because:\n",
    "\n",
    "1. **Non-parametric approach**: Makes no assumptions about data distribution or missing mechanism\n",
    "2. **Local similarity**: Imputes based on similar samples, preserving relationships between features\n",
    "3. **Handles correlations**: Leverages multivariate structure naturally present in welding data\n",
    "4. **Distance-based weighting**: Closer neighbors contribute more, reducing noise from dissimilar samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251f78b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=5, weights='distance')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "print(f\"Missing values before imputation: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values after imputation: {pd.DataFrame(X_imputed).isnull().sum().sum()}\")\n",
    "print(f\"Shape after imputation: {X_imputed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271fc14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(imputer, 'pca_model/imputer.pkl')\n",
    "print(\"Imputer saved to: pca_model/imputer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8715ed",
   "metadata": {},
   "source": [
    "## PCA Transformation\n",
    "\n",
    "Applying PCA to retain 90% of variance, reducing dimensionality while preserving most information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9ef5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.90, random_state=42)\n",
    "X_pca = pca.fit_transform(X_imputed)\n",
    "\n",
    "print(f\"Original features: {X_imputed.shape[1]}\")\n",
    "print(f\"PCA components: {X_pca.shape[1]}\")\n",
    "print(f\"Variance retained: {pca.explained_variance_ratio_.sum():.4f}\")\n",
    "print(f\"Dimensionality reduction: {(1 - X_pca.shape[1]/X_imputed.shape[1])*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c0ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pca, 'pca_model/pca_model.pkl')\n",
    "print(\"PCA model saved to: pca_model/pca_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e00c1cb",
   "metadata": {},
   "source": [
    "## Save Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710258b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_columns = [f'PC{i+1}' for i in range(X_pca.shape[1])]\n",
    "df_pca = pd.DataFrame(X_pca, columns=pc_columns, index=df_charpy_temp.index)\n",
    "df_pca['Charpy_Temp_C'] = y.values\n",
    "\n",
    "df_pca.to_csv('data/welddb_pca_charpy_temp.csv', index=False)\n",
    "print(f\"Transformed data saved to: data/welddb_pca_charpy_temp.csv\")\n",
    "print(f\"Shape: {df_pca.shape}\")\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b6a35",
   "metadata": {},
   "source": [
    "## Visualization 1: Explained Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d6ac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Cumulative variance\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "axes[0].plot(range(1, len(cumsum)+1), cumsum, 'bo-', linewidth=2)\n",
    "axes[0].axhline(y=0.90, color='r', linestyle='--', linewidth=2, label='90% threshold')\n",
    "axes[0].set_xlabel('Number of Components', fontsize=12)\n",
    "axes[0].set_ylabel('Cumulative Explained Variance', fontsize=12)\n",
    "axes[0].set_title('Cumulative Variance Explained', fontsize=13, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Individual variance\n",
    "n_show = min(15, len(pca.explained_variance_ratio_))\n",
    "axes[1].bar(range(1, n_show+1), pca.explained_variance_ratio_[:n_show], \n",
    "           alpha=0.7, color='steelblue', edgecolor='black')\n",
    "axes[1].set_xlabel('Component', fontsize=12)\n",
    "axes[1].set_ylabel('Explained Variance Ratio', fontsize=12)\n",
    "axes[1].set_title(f'Individual Component Variance (Top {n_show})', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/explained_variance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93edb9af",
   "metadata": {},
   "source": [
    "## Visualization 2: PCA Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec46f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# 2D scatter\n",
    "scatter = axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', \n",
    "                         alpha=0.6, edgecolors='k', linewidth=0.5)\n",
    "axes[0].set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%})', fontsize=12)\n",
    "axes[0].set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%})', fontsize=12)\n",
    "axes[0].set_title('First Two Principal Components', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "cbar = plt.colorbar(scatter, ax=axes[0])\n",
    "cbar.set_label('Charpy Temp (°C)', fontsize=11)\n",
    "\n",
    "# Correlation with target\n",
    "correlations = df_pca.drop('Charpy_Temp_C', axis=1).corrwith(df_pca['Charpy_Temp_C']).abs().sort_values(ascending=False)\n",
    "n_top = min(10, len(correlations))\n",
    "axes[1].barh(range(n_top), correlations.head(n_top).values, color='coral', alpha=0.7, edgecolor='black')\n",
    "axes[1].set_yticks(range(n_top))\n",
    "axes[1].set_yticklabels(correlations.head(n_top).index)\n",
    "axes[1].set_xlabel('Absolute Correlation', fontsize=12)\n",
    "axes[1].set_title('Top 10 PC Correlations with Charpy Temp', fontsize=13, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/pca_scatter_correlation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nStrongest correlation: {correlations.iloc[0]:.3f} ({correlations.index[0]})\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
